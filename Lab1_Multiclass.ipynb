{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qrIF2jJmGQnh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "def load_dataset():\n",
        "    train_dataset = h5py.File('Train.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"images\"][:])\n",
        "    train_set_y_orig = np.array(train_dataset[\"labels\"][:])\n",
        "\n",
        "    test_dataset = h5py.File('Test.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"images\"][:])\n",
        "    test_set_y_orig = np.array(test_dataset[\"labels\"][:])\n",
        "\n",
        "    classes = np.unique(train_set_y_orig)\n",
        "\n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "\n",
        "# Load and preprocess data\n",
        "train_x_orig, train_y_orig, test_x_orig, test_y_orig, classes = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "pzQa-ZaHLj-E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_train = train_x_orig.shape[0]\n",
        "m_test  = test_x_orig.shape[0]\n",
        "num_px  = train_x_orig.shape[1]\n",
        "\n",
        "print(\"Number of training examples: m_train = \" + str(m_train))\n",
        "print(\"Number of testing examples: m_test = \" + str(m_test))\n",
        "print(\"Height/Width of each image: num_px = \" + str(num_px))\n",
        "print(\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
        "print(\"train_x shape: \" + str(train_x_orig.shape))\n",
        "print(\"train_y shape: \" + str(train_y_orig.shape))\n",
        "print(\"test_x shape: \" + str(test_x_orig.shape))\n",
        "print(\"test_y shape: \" + str(test_y_orig.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuUgKVyyNNFA",
        "outputId": "e00461d1-9402-4a07-dc93-9f061f287ba7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: m_train = 2626\n",
            "Number of testing examples: m_test = 120\n",
            "Height/Width of each image: num_px = 128\n",
            "Each image is of size: (128, 128, 3)\n",
            "train_x shape: (2626, 128, 128, 3)\n",
            "train_y shape: (1, 2626)\n",
            "test_x shape: (120, 128, 128, 3)\n",
            "test_y shape: (1, 120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x_orig[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBHsEi6LNglH",
        "outputId": "f731bed3-ccbb-41c3-90b4-6629ce3d79ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### START CODE HERE ### (â‰ˆ 2 lines of code)\n",
        "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T\n",
        "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
        "### END CODE HERE ###\n",
        "\n",
        "print(\"train_x_flatten shape: \" + str(train_x_flatten.shape))\n",
        "print(\"train_y shape: \" + str(train_y_orig.shape))\n",
        "print(\"test_x_flatten shape: \" + str(test_x_flatten.shape))\n",
        "print(\"test_y shape: \" + str(test_y_orig.shape))\n",
        "print(\"Sanity check after reshaping: \" + str(train_x_flatten[0:5, 0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPDh5qvQNh-j",
        "outputId": "12619e31-8b5d-40c1-a263-c6750b8df5b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x_flatten shape: (49152, 2626)\n",
            "train_y shape: (1, 2626)\n",
            "test_x_flatten shape: (49152, 120)\n",
            "test_y shape: (1, 120)\n",
            "Sanity check after reshaping: [213 216 224 212 214]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_x = train_x_flatten/255.\n",
        "test_set_x = test_x_flatten/255."
      ],
      "metadata": {
        "id": "CJfLGtxrN9Ul"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_with_zeros(dim, n_classes):\n",
        "    W = np.zeros((dim, n_classes))\n",
        "    b = np.zeros((n_classes, 1))\n",
        "    return W, b"
      ],
      "metadata": {
        "id": "vLZ1D8-0O4Cp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def softmax(Z):\n",
        "    # Stability trick: Subtract max to prevent overflow issues with exp.\n",
        "    Z_exp = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
        "    return Z_exp / np.sum(Z_exp, axis=0, keepdims=True)\n",
        "\n",
        "def compute_cost(A, Y):\n",
        "    m = Y.shape[1]\n",
        "    cost = -np.sum(Y * np.log(A)) / m\n",
        "    return cost\n",
        "def forward_propagation(X, W, b):\n",
        "    Z = np.dot(W.T, X) + b\n",
        "    A = softmax(Z)\n",
        "    return A\n",
        "def backward_propagation(X, Y, A):\n",
        "    m = X.shape[1]\n",
        "    dZ = A - Y\n",
        "    dw = np.dot(X, dZ.T) / m\n",
        "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
        "    gradients = {\"dw\": dw, \"db\": db}\n",
        "    return gradients\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bGE4w6bOWsu8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "z = np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])\n",
        "print(\"Softmax output:\\n\", softmax(z))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITSUAqOhpsnt",
        "outputId": "abd3da49-877b-4649-96be-81fb53186f59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax output:\n",
            " [[0.33333333 0.33333333 0.33333333]\n",
            " [0.33333333 0.33333333 0.33333333]\n",
            " [0.33333333 0.33333333 0.33333333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(W, b, gradients, learning_rate):\n",
        "    W -= learning_rate * gradients['dw']\n",
        "    b -= learning_rate * gradients['db']\n",
        "    return W, b"
      ],
      "metadata": {
        "id": "qU_TtGs9ojlo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize(W, b, X, Y, num_iterations, learning_rate, print_cost=False):\n",
        "    costs = []\n",
        "    for i in range(num_iterations):\n",
        "        A = forward_propagation(X, W, b)\n",
        "        cost = compute_cost(A, Y)\n",
        "        gradients = backward_propagation(X, Y, A)\n",
        "        W, b = update_parameters(W, b, gradients, learning_rate)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "            if print_cost:\n",
        "                print(f\"Cost after iteration {i}: {cost}\")\n",
        "\n",
        "    params = {\"W\": W, \"b\": b}\n",
        "    grads = {\"dw\": gradients[\"dw\"], \"db\": gradients[\"db\"]}\n",
        "    return params, grads, costs"
      ],
      "metadata": {
        "id": "Wlm8o_gOonYE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(W, b, X):\n",
        "    A = forward_propagation(X, W, b)\n",
        "    Y_prediction = np.argmax(A, axis=0)\n",
        "    return Y_prediction"
      ],
      "metadata": {
        "id": "z_A4fV11oqtf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=2000, learning_rate=0.0001, print_cost=True):\n",
        "    num_features = train_set_x.shape[0]\n",
        "    num_classes = train_set_y.shape[0]\n",
        "\n",
        "    W, b = initialize_with_zeros(num_features, num_classes)\n",
        "    parameters, grads, costs = optimize(W, b, train_set_x, train_set_y, num_iterations, learning_rate, print_cost)\n",
        "\n",
        "    W = parameters[\"W\"]\n",
        "    b = parameters[\"b\"]\n",
        "\n",
        "    Y_prediction_test = predict(W, b, test_set_x)\n",
        "    Y_prediction_train = predict(W, b, train_set_x)\n",
        "\n",
        "    # Calculate train/test accuracy\n",
        "    train_accuracy = np.mean(Y_prediction_train == np.argmax(train_set_y, axis=0)) * 100\n",
        "    test_accuracy = np.mean(Y_prediction_test == np.argmax(test_set_y, axis=0)) * 100\n",
        "\n",
        "    print(\"train accuracy: {} %\".format(train_accuracy))\n",
        "    print(\"test accuracy: {} %\".format(test_accuracy))\n",
        "\n",
        "    d = {\"costs\": costs,\n",
        "         \"Y_prediction_test\": Y_prediction_test,\n",
        "         \"Y_prediction_train\": Y_prediction_train,\n",
        "         \"W\": W,\n",
        "         \"b\": b,\n",
        "         \"learning_rate\": learning_rate,\n",
        "         \"num_iterations\": num_iterations}\n",
        "\n",
        "    return d\n"
      ],
      "metadata": {
        "id": "YTpkFdyAowoY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y"
      ],
      "metadata": {
        "id": "cWChMjlOlWlF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_one_hot = convert_to_one_hot(train_y_orig, classes.size)\n",
        "test_y_one_hot = convert_to_one_hot(test_y_orig, classes.size)"
      ],
      "metadata": {
        "id": "Zkh_txOXlS4_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = model(train_set_x, train_y_one_hot, test_set_x, test_y_one_hot, num_iterations=2000, learning_rate=0.0001, print_cost=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AehgWvDymMky",
        "outputId": "1caceee8-4a95-4e35-9645-2840334b5385"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 1.6094379124340998\n",
            "Cost after iteration 100: 1.4809790230418693\n",
            "Cost after iteration 200: 1.4149051647574025\n",
            "Cost after iteration 300: 1.372336489381762\n",
            "Cost after iteration 400: 1.3416440214636625\n",
            "Cost after iteration 500: 1.3179134628118345\n",
            "Cost after iteration 600: 1.2986900128268086\n",
            "Cost after iteration 700: 1.2825935558710222\n",
            "Cost after iteration 800: 1.2687788229796593\n",
            "Cost after iteration 900: 1.256693708408014\n",
            "Cost after iteration 1000: 1.2459591212943677\n",
            "Cost after iteration 1100: 1.2363042203395442\n",
            "Cost after iteration 1200: 1.2275291817324143\n",
            "Cost after iteration 1300: 1.219482639069279\n",
            "Cost after iteration 1400: 1.2120473979524748\n",
            "Cost after iteration 1500: 1.2051310440363387\n",
            "Cost after iteration 1600: 1.1986595646613742\n",
            "Cost after iteration 1700: 1.1925728930047992\n",
            "Cost after iteration 1800: 1.1868217174492195\n",
            "Cost after iteration 1900: 1.1813651469692914\n",
            "train accuracy: 54.18888042650419 %\n",
            "test accuracy: 53.333333333333336 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve W and b from the model output\n",
        "import random\n",
        "W = d[\"W\"]\n",
        "b = d[\"b\"]\n",
        "\n",
        "# Now you can use W and b in your prediction code\n",
        "random_index = random.randint(0, test_set_x.shape[1] - 1)\n",
        "random_image = test_set_x[:, random_index].reshape(-1, 1)\n",
        "\n",
        "# Make a prediction on the random image\n",
        "predicted_probabilities = predict(W, b, random_image)  # Assuming predict returns probabilities\n",
        "predicted_label = np.argmax(predicted_probabilities)  # Convert probabilities to class label\n",
        "\n",
        "# Get the actual label\n",
        "actual_label = np.argmax(test_y_orig[:, random_index])  # Extract actual label from one-hot encoded\n",
        "\n",
        "# Display the predicted and actual labels\n",
        "print(f\"Predicted label: {predicted_label}\")\n",
        "print(f\"Actual label: {actual_label}\")"
      ],
      "metadata": {
        "id": "Vp7j16clOTLG",
        "outputId": "27dc9477-5be4-49f1-cfc2-01f6affdcc2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 0\n",
            "Actual label: 0\n"
          ]
        }
      ]
    }
  ]
}